{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "from typing import List, Tuple, Any, Union\n",
    "from functools import reduce\n",
    "from mcl import Fr, G1\n",
    "\n",
    "sys.path.insert(1, '/home/jawitold/mcl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_file_id(file_path: str) -> bytes:\n",
    "    seed__ = b\"\"\n",
    "    with open(file_path, 'rb') as file:\n",
    "        seed__ += file.readline()\n",
    "    return G1().hashAndMapTo(seed__).getStr()\n",
    "\n",
    "\n",
    "def li_exp(x_: Fr, A: List[Tuple[Fr, Fr]]) -> G1:\n",
    "    neutral_element_multiplier__ = G1().hashAndMapTo(b'1') - G1().hashAndMapTo(b'1')\n",
    "    neutral_element_sum_ = Fr.setHashOf(b'1') / Fr.setHashOf(b'1')\n",
    "    return reduce(lambda res_1, q: res_1 + (\n",
    "            q[1] * reduce(lambda res_2, p: res_2 * (x_ - p[0]) / (q[0] - p[0]) if q[0] != p[0] else res_2, A,\n",
    "                          neutral_element_sum_)), A, neutral_element_multiplier__)\n",
    "\n",
    "\n",
    "def get_unique_random_fr(existing_: List[Fr]) -> Fr:\n",
    "    while True:\n",
    "        rand_value_ = Fr.rnd()\n",
    "        if all(m_i_ != rand_value_ for m_i_ in existing_):\n",
    "            return rand_value_\n",
    "\n",
    "\n",
    "def get_polynomial_value(coefficients_: List[Fr], x_value_: Fr) -> Fr:\n",
    "    value_ = Fr()\n",
    "    for coefficient_ in reversed(coefficients_):\n",
    "        value_ = value_ * x_value_ + coefficient_\n",
    "    return value_\n",
    "\n",
    "\n",
    "def custom_encoder(obj: Any) -> Union[str, bytes]:\n",
    "    if hasattr(obj, 'getStr'):\n",
    "        return obj.getStr()\n",
    "    elif isinstance(obj, bytes):\n",
    "        return obj.decode('latin-1')\n",
    "    raise TypeError(\"Object of unsupported type\")\n",
    "\n",
    "\n",
    "def save_to_json(file_path: str, value: Any) -> None:\n",
    "    with open(file_path, 'w') as json_file:\n",
    "        json_file.write(json.dumps(value, default=custom_encoder))\n",
    "\n",
    "\n",
    "def load_from_json(file_path: str) -> Any:\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, seed: bytes, file_path: str) -> None:\n",
    "        self.key_file__ = None\n",
    "        self.m_ = None\n",
    "        self.secret_key_ = None\n",
    "        self.raw_m_ = None\n",
    "        self.g__ = None\n",
    "        self.file_path = file_path\n",
    "        self.setup(seed)\n",
    "\n",
    "    def check_proof(self, proof_file__: G1) -> bool:\n",
    "        return self.key_file__ == proof_file__\n",
    "\n",
    "    def split_file_into_chunks(self, chunk_size: int = 8) -> None:\n",
    "        self.raw_m_ = []\n",
    "        with open(self.file_path, 'rb') as file:\n",
    "            while chunk := file.read(chunk_size):\n",
    "                self.raw_m_.append(chunk)\n",
    "        self.convert_chunks_to_fr()\n",
    "\n",
    "    def convert_chunks_to_fr(self):\n",
    "        self.m_ = []\n",
    "        for i, chunk in enumerate(self.raw_m_):\n",
    "            value_ = Fr()\n",
    "            value_.setInt(int.from_bytes(chunk, 'little') + i)\n",
    "            self.m_.append(value_)\n",
    "\n",
    "    def setup(self, seed: bytes) -> None:\n",
    "        self.g__ = G1().hashAndMapTo(seed)\n",
    "        self.secret_key_ = Fr.rnd()\n",
    "\n",
    "    def get_polynomial(self) -> List[Fr]:\n",
    "        file_id__ = get_file_id(self.file_path)\n",
    "        return [Fr.setHashOf(bytes(self.secret_key_) + file_id__ + bytes(i)) for i in range(len(self.m_) + 1)]\n",
    "\n",
    "    def tag_blocks(self) -> List[Tuple[bytes, Fr]]:\n",
    "        coefficients_ = self.get_polynomial()\n",
    "        return [(raw, get_polynomial_value(coefficients_, m_value_)) for raw, m_value_ in\n",
    "                zip(self.raw_m_, self.m_)]\n",
    "\n",
    "    def generate_challenge(self) -> Tuple[G1, Fr, G1]:\n",
    "        coefficients_ = self.get_polynomial()\n",
    "        random_value_ = Fr.rnd()\n",
    "        unique_random_value_ = get_unique_random_fr(self.m_)\n",
    "        self.key_file__ = self.g__ * (random_value_ * get_polynomial_value(coefficients_, unique_random_value_))\n",
    "        return self.g__ * random_value_, unique_random_value_, self.g__ * (\n",
    "                random_value_ * get_polynomial_value(coefficients_, Fr()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Claass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Cloud:\n",
    "    def __init__(self) -> None:\n",
    "        self.tagged_file = None\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_tagged_file(json_data: List[List[Union[str, bytes]]]) -> List[Tuple[bytes, Fr]]:\n",
    "        deserialized_data = []\n",
    "        for item in json_data:\n",
    "            if len(item) == 2:\n",
    "                raw_data = bytes(item[0], 'latin-1')\n",
    "                fr_value_ = Fr()\n",
    "                fr_value_.setStr(bytes(item[1], 'latin-1'))\n",
    "                deserialized_data.append((raw_data, fr_value_))\n",
    "        return deserialized_data\n",
    "\n",
    "    def convert_chunks_to_fr(self) -> None:\n",
    "        for i, (chunk, tag_) in enumerate(self.tagged_file):\n",
    "            value_ = Fr()\n",
    "            value_.setInt(int.from_bytes(chunk, 'little') + i)\n",
    "            self.tagged_file[i] = (value_, tag_)\n",
    "\n",
    "    def upload_file(self, tagged_file: List[Tuple[bytes, Fr]]) -> None:\n",
    "        self.tagged_file = tagged_file\n",
    "        self.convert_chunks_to_fr()\n",
    "\n",
    "    def generate_proof(self, challenge: Tuple[G1, Fr, G1]) -> G1:\n",
    "        gr__, x_value_, grlf_0__ = challenge\n",
    "        ksi_ = [(m_value_, gr__ * tag_) for m_value_, tag_ in self.tagged_file]\n",
    "        ksi_.append((Fr(), grlf_0__))\n",
    "        return li_exp(x_value_, ksi_)\n",
    "\n",
    "    @staticmethod\n",
    "    def deserialize_challenge(json_data: List[str]) -> Tuple[G1, Fr, G1]:\n",
    "        g_value__ = G1()\n",
    "        x_value_ = Fr()\n",
    "        g_coefficient__ = G1()\n",
    "\n",
    "        if len(json_data) == 3:\n",
    "            g_value__.setStr(bytes(json_data[0], 'latin-1'))\n",
    "            x_value_.setStr(bytes(json_data[1], 'latin-1'))\n",
    "            g_coefficient__.setStr(bytes(json_data[2], 'latin-1'))\n",
    "        return g_value__, x_value_, g_coefficient__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup parameters\n",
    "\n",
    "file_path = '../data/randomfile_1K'\n",
    "seed_value = b'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protocol parties instances\n",
    "\n",
    "client_instance = Client(seed_value, file_path)\n",
    "cloud_instance = Cloud()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client splits file into chunks, generates tags and sends it to cloud\n",
    "\n",
    "client_instance.split_file_into_chunks()\n",
    "tagged_file = client_instance.tag_blocks()\n",
    "save_to_json('../data/tagged_file.json', tagged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud read tagged file, deserializes and saves\n",
    "\n",
    "loaded_data = load_from_json('../data/tagged_file.json')\n",
    "cloud_tagged_file = cloud_instance.deserialize_tagged_file(loaded_data)\n",
    "cloud_instance.upload_file(cloud_tagged_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client prepares the challenge and sends it to Cloud\n",
    "\n",
    "challenge = client_instance.generate_challenge()\n",
    "save_to_json('../data/challenge.json', challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud computes proof\n",
    "\n",
    "loaded_challenge = load_from_json('../data/challenge.json')\n",
    "cloud_challenge = cloud_instance.deserialize_challenge(loaded_challenge)\n",
    "proof_file__ = cloud_instance.generate_proof(cloud_challenge)\n",
    "save_to_json('../data/proof_file.json', proof_file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof verified!\n"
     ]
    }
   ],
   "source": [
    "# Client checks the proof\n",
    "\n",
    "loaded_proof_file__ = load_from_json('../data/proof_file.json')\n",
    "if isinstance(loaded_proof_file__, str):\n",
    "    proof_file__ = G1()\n",
    "    proof_file__.setStr(bytes(loaded_proof_file__, 'latin-1'))\n",
    "    if client_instance.check_proof(proof_file__):\n",
    "        print(\"Proof verified!\")\n",
    "    else:\n",
    "        print(\"Proof failed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
